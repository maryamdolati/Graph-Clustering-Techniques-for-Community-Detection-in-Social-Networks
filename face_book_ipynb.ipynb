{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "755c25b2",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "adf20d1700f84b0791026dec522b2bb0",
            "dfc8c9d6cfcc4e1e8e0106596e739cd8"
          ]
        },
        "id": "755c25b2",
        "outputId": "eb71c04d-c02f-47f6-dcae-b46a3adbf6b8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adf20d1700f84b0791026dec522b2bb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing transition probabilities:   0%|          | 0/4039 [00:01<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfc8c9d6cfcc4e1e8e0106596e739cd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing transition probabilities:   0%|          | 0/4039 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         Modularity       NMI  ARI\n",
            "Hierarchical Clustering    0.007645  0.406231  0.0\n",
            "Spectral Clustering        0.009433  0.392169  0.0\n",
            "Louvain Method             0.201804  0.458522  0.0\n",
            "DeepWalk                   0.223777  0.421839  0.0\n",
            "Node2Vec                   0.246428  0.414344  0.0\n",
            "GCN                        0.006494  0.395117  0.0\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
        "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_rand_score as ARI\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import from_networkx\n",
        "from community import community_louvain\n",
        "from node2vec import Node2Vec\n",
        "\n",
        "file_path = r'D:\\New folder (4)\\facebook_combined.txt\\facebook_combined.txt'\n",
        "\n",
        "G = nx.read_edgelist(file_path, nodetype=int)\n",
        "\n",
        "node_features = np.random.rand(G.number_of_nodes(), 16)\n",
        "\n",
        "data = from_networkx(G)\n",
        "data.x = torch.tensor(node_features, dtype=torch.float)\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 16)\n",
        "        self.conv2 = GCNConv(16, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "def compute_node_embeddings(data, num_clusters):\n",
        "    model = GCN(data.x.shape[1], num_clusters)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        initial_embeddings = model(data.x, data.edge_index)\n",
        "        kmeans = KMeans(n_clusters=num_clusters).fit(initial_embeddings.detach().numpy())\n",
        "        labels = torch.tensor(kmeans.labels_, dtype=torch.long)\n",
        "\n",
        "    for epoch in range(200):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(data.x, data.edge_index).numpy()\n",
        "    return embeddings\n",
        "\n",
        "num_clusters = 10\n",
        "\n",
        "gcn_embeddings = compute_node_embeddings(data, num_clusters)\n",
        "\n",
        "kmeans = KMeans(n_clusters=num_clusters).fit(gcn_embeddings)\n",
        "hierarchical = AgglomerativeClustering(n_clusters=num_clusters).fit(gcn_embeddings)\n",
        "spectral = SpectralClustering(n_clusters=num_clusters, affinity='nearest_neighbors').fit(gcn_embeddings)\n",
        "louvain = community_louvain.best_partition(G)\n",
        "\n",
        "\n",
        "def deepwalk_embedding(G, dimensions=64, walk_length=30, num_walks=200, workers=4):\n",
        "    node2vec = Node2Vec(G, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, workers=workers)\n",
        "    model = node2vec.fit(window=10, min_count=1)\n",
        "    embeddings = np.array([model.wv[str(node)] for node in G.nodes()])\n",
        "    return embeddings\n",
        "\n",
        "deepwalk_embeddings = deepwalk_embedding(G)\n",
        "\n",
        "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4).fit()\n",
        "node2vec_embeddings = np.array([node2vec.wv[str(node)] for node in G.nodes()])\n",
        "\n",
        "deepwalk_clusters = KMeans(n_clusters=num_clusters).fit_predict(deepwalk_embeddings)\n",
        "node2vec_clusters = KMeans(n_clusters=num_clusters).fit_predict(node2vec_embeddings)\n",
        "\n",
        "\n",
        "def compute_metrics(G, labels):\n",
        "    modularity = nx.algorithms.community.quality.modularity(G, [list(np.where(labels == c)[0]) for c in np.unique(labels)])\n",
        "    nmi = NMI(list(G.nodes), labels)\n",
        "    ari = ARI(list(G.nodes), labels)\n",
        "    return modularity, nmi, ari\n",
        "\n",
        "metrics = {\n",
        "    'Hierarchical Clustering': compute_metrics(G, hierarchical.labels_),\n",
        "    'Spectral Clustering': compute_metrics(G, spectral.labels_),\n",
        "    'Louvain Method': compute_metrics(G, list(louvain.values())),\n",
        "    'DeepWalk': compute_metrics(G, deepwalk_clusters),\n",
        "    'Node2Vec': compute_metrics(G, node2vec_clusters),\n",
        "    'GCN': compute_metrics(G, kmeans.labels_)\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(metrics, index=['Modularity', 'NMI', 'ARI']).transpose()\n",
        "\n",
        "\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d9922f3",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "39e2672889cd4e249e656f96e3d04694",
            "22c96c47446442e4be4dc4f881882113"
          ]
        },
        "id": "3d9922f3",
        "outputId": "0ea9a7c1-2253-46ba-bbbe-eb5a4e2e9e0e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39e2672889cd4e249e656f96e3d04694",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing transition probabilities:   0%|          | 0/4039 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22c96c47446442e4be4dc4f881882113",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing transition probabilities:   0%|          | 0/4039 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         Conductance\n",
            "KMeans                      0.894359\n",
            "Hierarchical Clustering     0.895845\n",
            "Spectral Clustering         0.895565\n",
            "Louvain Method              0.745604\n",
            "DeepWalk                    0.621720\n",
            "Node2Vec                    0.589396\n",
            "GCN                         0.894359\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
        "from sklearn.metrics import normalized_mutual_info_score as NMI, adjusted_rand_score as ARI\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import from_networkx\n",
        "from community import community_louvain\n",
        "from node2vec import Node2Vec\n",
        "\n",
        "file_path = r'D:\\New folder (4)\\facebook_combined.txt\\facebook_combined.txt'\n",
        "\n",
        "G = nx.read_edgelist(file_path, nodetype=int)\n",
        "\n",
        "node_features = np.random.rand(G.number_of_nodes(), 16)\n",
        "\n",
        "data = from_networkx(G)\n",
        "data.x = torch.tensor(node_features, dtype=torch.float)\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 16)\n",
        "        self.conv2 = GCNConv(16, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "def compute_node_embeddings(data, num_clusters):\n",
        "    model = GCN(data.num_node_features, num_clusters)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        initial_embeddings = model(data.x, data.edge_index)\n",
        "        kmeans = KMeans(n_clusters=num_clusters).fit(initial_embeddings.detach().numpy())\n",
        "        labels = torch.tensor(kmeans.labels_, dtype=torch.long)\n",
        "\n",
        "    for epoch in range(200):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(data.x, data.edge_index).numpy()\n",
        "    return embeddings\n",
        "\n",
        "def conductance(G, clusters):\n",
        "    total_cut = 0\n",
        "    for cluster in clusters:\n",
        "        cut = nx.algorithms.cuts.cut_size(G, cluster)\n",
        "        volume = sum(dict(G.degree(cluster)).values())\n",
        "        if volume == 0:\n",
        "            continue\n",
        "        total_cut += cut / volume\n",
        "    return total_cut / len(clusters)\n",
        "\n",
        "num_clusters = 10\n",
        "gcn_embeddings = compute_node_embeddings(data, num_clusters)\n",
        "\n",
        "kmeans = KMeans(n_clusters=num_clusters).fit(gcn_embeddings)\n",
        "hierarchical = AgglomerativeClustering(n_clusters=num_clusters).fit(gcn_embeddings)\n",
        "spectral = SpectralClustering(n_clusters=num_clusters, affinity='nearest_neighbors').fit(gcn_embeddings)\n",
        "louvain = community_louvain.best_partition(G)\n",
        "\n",
        "\n",
        "def deepwalk_embedding(G, dimensions=64, walk_length=30, num_walks=200, workers=4):\n",
        "    node2vec = Node2Vec(G, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, workers=workers)\n",
        "    model = node2vec.fit(window=10, min_count=1)\n",
        "    embeddings = np.array([model.wv[str(node)] for node in G.nodes()])\n",
        "    return embeddings\n",
        "\n",
        "deepwalk_embeddings = deepwalk_embedding(G)\n",
        "\n",
        "\n",
        "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4).fit()\n",
        "node2vec_embeddings = np.array([node2vec.wv[str(node)] for node in G.nodes()])\n",
        "\n",
        "deepwalk_clusters = KMeans(n_clusters=num_clusters).fit_predict(deepwalk_embeddings)\n",
        "node2vec_clusters = KMeans(n_clusters=num_clusters).fit_predict(node2vec_embeddings)\n",
        "\n",
        "def compute_metrics(G, labels):\n",
        "    conductance_value = conductance(G, [list(np.where(labels == c)[0]) for c in np.unique(labels)])\n",
        "    return  conductance_value\n",
        "\n",
        "metrics = {\n",
        "    'KMeans': compute_metrics(G, kmeans.labels_),\n",
        "    'Hierarchical Clustering': compute_metrics(G, hierarchical.labels_),\n",
        "    'Spectral Clustering': compute_metrics(G, spectral.labels_),\n",
        "    'Louvain Method': compute_metrics(G, np.array(list(louvain.values()))),\n",
        "    'DeepWalk': compute_metrics(G, deepwalk_clusters),\n",
        "    'Node2Vec': compute_metrics(G, node2vec_clusters),\n",
        "    'GCN': compute_metrics(G, kmeans.labels_)\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(metrics, index=['Conductance']).transpose()\n",
        "\n",
        "\n",
        "print(df)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}